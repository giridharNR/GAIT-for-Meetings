This folder contains code for the CATS (Coherence Aware Text Segmentation) tool, which performs text segmentation. For details about the model, please refer to the AAAI 2020 paper [Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text Segmentation](https://arxiv.org/abs/2001.00891).


## Setup

Create a conda environment using the `environment.yml` file.

* `conda create -n cats -f environment.yml`
* `conda activate cats`

Download data folder:
* Download the data folder from `data_drive_link`
* Add the `data\` folder inside the `CATS\` folder

## Make Predictions

Run the following command
* `bash segment.sh input_dir output_dir`

Arguments:

* `input_dir`: path to the directory that contains textual documents that need to be segmented
* `output_dir`: path to the directory in which the segmented documents will be stored

The script `segment.sh`  sequentially executes two Python scripts:

* `cats_preprocess.py`: converts the raw textual documents into data structures (concretely, TensorFlow Records) consumed by the pre-trained neural segmentation models. Upon completion, this script (temporarily) generates two special files, ` records.tf` and `blocks.pkl` in the output dir. These serialized data structures are then the input for the second script.
* `cats_predict.py`: generates segmentation predictions (takes as input `records.tf` and `blocks.pkl` generated by `cats_preprocess.py`) and creates segmented variants of the input files. The segmented documents are saved to the output dir. After the segmented textual documents have been generated, the script `segment.sh` deletes the temporary serialization files (`records.tf` and `blocks.pkl`) generated by `cats_preprocess.py`.

## Create the files for action item classification

* Update the paths in the generate_segmented_files_and_analysis.py accordingly, especially the input file source. The `root_dir` in the python script must be the directory of CATS output.
* run `python generate_segmented_files_and_analysis.py`
